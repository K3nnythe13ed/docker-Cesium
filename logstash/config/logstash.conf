input {
	beats {
		port => 5044
    codec => "json"
	}
}

filter {

  # vessel data from AISHub
  if [type] == "vessel" {
    
    mutate {
      convert => { 
        "LONGITUDE" => "float" 
        "LATITUDE" => "float" 
        "DRAUGHT" => "float" 
      }
      # move to "location" object, so we can use geo_point
      rename => {
        "LONGITUDE" => "[LOCATION][lon]"
        "LATITUDE" => "[LOCATION][lat]"
      }
    }
      
    # time handling, cut GMT
    mutate {
      gsub => ["TIME", " GMT", ""]
    }
    date {
      match => ["TIME", "ISO8601", "yyyy-MM-dd HH:mm:ss"]
      timezone => 'UTC'
      remove_field => [ "TIME" ]
    }

    # Set id based on MMSI + timestamp
    mutate {
      add_field => { "id" => "%{MMSI}_%{@timestamp}" }
      add_field => { "[@metadata][index]" => "logstash-%{+YYYY.MM.dd}" }
    }
  }

  if [type] == "warehouse" {
    # Set id based on MMSI + timestamp
    mutate {
      add_field => { "id" => "%{[properties][LocID]}" }
      add_field => { "[@metadata][index]" => "logstash-constant" }
      
    }
  }
}


output {
	elasticsearch {
		hosts => "elasticsearch:9200"
    document_id => "%{[id]}"
    index => "%{[@metadata][index]}"
    manage_template => false

    # TODO: pipeline, https://www.elastic.co/guide/en/logstash/5.0/plugins-outputs-elasticsearch.html#plugins-outputs-elasticsearch-pipeline
    pipeline => "riskmap-pipeline"     
	}
}

